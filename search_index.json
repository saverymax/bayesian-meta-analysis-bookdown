[["index.html", "Bayesian meta-analysis of ivermectin as a treatment for COVID-19 1 Technical preface", " Bayesian meta-analysis of ivermectin as a treatment for COVID-19 Max Savery 1 Technical preface This is the bookdown (Xie 2022) report for my meta-analysis of ivermectin as a treatment for COVID-19. This was originally intended as my course project for the meta-analysis course from KU Leuven.The code for the report is hosted at https://github.com/saverymax/bayesian-meta-analysis-bookdown. To locally render the book, run install.packages(&quot;bookdown&quot;) bookdown::render_book(&#39;index.Rmd&#39;, &#39;bookdown::pdf_book&#39;) This report reviews Bayesian methods for estimating random effect models for meta-analysis, with a particular focus on the effect of prior information. Then, using summary data from studies conducted to measure the effect of ivermectin as a treatment for COVID-19, we demonstrate the use of Bayesian methods for meta-analysis, experimenting with the effect of different priors on the between-study variance. The summary data for ivermectin is provided in a blog post by the statistician Andrew Gelman (Gelman 2022). In the post, Gelman reconstructs a meta-analysis on the effect of ivermectin. He demonstrates how the selection of the prior for the between-study variance can influence conclusions of the meta-analysis, in this case the extent to which ivermectin has a positive effect on treating COVID-19. We take his discussion of this topic as a starting point for this report. Given that there was a large amount of misinformation regarding ivermectin and various pseudo-scientific studies regarding this topic (Reardon 2021), it is quite an interesting case study of the role that Bayesian modelling can play in meta-analyses. All R code and Markdown files used to conduct the analysis presented in this report can be found at https://github.com/saverymax/bayesian-meta-analysis. References "],["bayesian-methods-for-meta-analysis.html", "2 Bayesian methods for Meta-analysis 2.1 Why Bayesian? 2.2 Informative priors 2.3 Weakly informative priors", " 2 Bayesian methods for Meta-analysis 2.1 Why Bayesian? Fixed effect models for meta-analysis are suitable when the studies are homogeneous and can be assumed to share an overall effect. However, as described in Higgins, Thompson, and Spiegelhalter (2009), fixed effect models fail when the overall effect is heterogenous between studies. It is then necessary to turn to random effect models so as to be able to estimate study-specific effects. However, to fully take advantage of these models, such as for the purpose of generating posteriors and uncertainty intervals around the study-specific effects or to incorporate prior information, Bayesian methods are required. Bayesian methods allow us to combine a likelihood based on observed data and a prior distribution model which incorporates previous beliefs and historical information. In the prior, we can incorporate information from previous studies, our beliefs about the size of the effect we are studying, or use the prior to make a conservative estimate (Rhodes et al. 2016). In this way, using a Bayesian approach we can expand the random effects model to more carefully consider the observed effects from any given meta-analysis. Furthermore, the use of Bayesian methods lends itself to cases in which the sample size is relatively small. When we underestimate the between-study variance, we produce over-confident estimates, in that our confidence intervals are too small (Harrer et al. 2021). Furthermore, Bayesian estimation methods avoid estimates between-study variance that approach 0, which, in the Maximum Likelihood or Restriced Maximum Likelihood context, is not uncommon when estimating random-effects models with small sample sizes (Chung, Rabe-Hesketh, and Choi 2013). Given the advantages of the random effects model in the Bayesian framework, as opposed to the fixed effects model, we now proceed to describe Bayesian inference in the context of meta-analysis and random effects models. Here we provide a brief introduction to Bayesian methods in general and then describe their use in conducting meta analyses. In the Bayesian framework, the likelihood of observed data is combined with a prior distribution that represents historical information. This is commonly written as \\[\\begin{gather} p(\\theta|y) \\propto p(y|\\theta)p(\\theta) \\tag{2.1} \\end{gather}\\] where \\(\\theta\\) represents a vector of the parameters in our model and \\(y\\) the vector of observations (Gelman et al. 2013). This distribution is referred to as the posterior density. \\(\\propto\\) represents the proportionality due to the normalizing constant which makes the posterior a proper density. To generate samples from this posterior distribution, various sampling techniques can be used. Due to the background required to explain these methods and the focus of this report on meta-analysis, the sampling techniques are not discussed in detail here. However, because we will conduct a meta-analysis using the Bayesian modelling software Stan (Carpenter et al. 2017), it is worth mentioning the sampler used there: the No-U-Turn Sampler (NUTS) is used (Hoffman and Gelman 2014), an improvement on the Hamiltonian Monte Carlo method. Following (Williams, Rast, and Bürkner 2018), we now describe the hierarchical model used for conducting a random effects Bayesian meta-analysis. In this formulation, each study will have a particular mean and variance \\[\\begin{gather} y_i \\sim N(\\theta_i, \\sigma_i^2) \\\\ \\theta_i \\sim N(\\mu, \\tau^2) \\\\ (\\mu, \\tau^2) \\sim prior(.) \\end{gather}\\] where \\(y_i\\) is the effect we observe in each study \\(i=1,...,N\\), \\(\\theta_i\\) is the mean effect within the context of study \\(i\\), \\(\\sigma_i^2\\) is the variance within that study, \\(\\mu\\) is the mean effect of the studies, and \\(\\tau^2\\) is the between-study variance. The effect for a given study \\(i\\) is drawn from \\(N(\\mu, \\tau^2)\\), as opposed to being fixed (as in the fixed effect model). Notice that the effect from each study, \\(\\theta_i\\), shares a distribution \\(N(\\mu, \\tau^2)\\) with all other studies (Harrer et al. 2021) Using Equation (2.1), the joint posterior density of the random effects model will be \\[\\begin{gather} p(\\theta, \\mu, \\tau^2|y) \\propto p(y|\\theta, \\mu, \\tau^2)p(\\theta, \\mu, \\tau^2) = \\prod_{i=1}^{k}p(y_i|\\theta_i,\\sigma_i^2)p(\\theta_i|\\mu,\\tau^2)p(\\mu, \\tau^2) \\end{gather}\\] We then must consider which priors to use for \\(\\mu\\) and \\(\\tau^2\\). This is a fairly important question. Gelman, Simpson, and Betancourt (2017) discuss a case in which the choice of a uniform prior leads to completely incorrect posterior estimates and therefore misleading conclusions of a study. They state This implies that in the small-sample world of meta-analysis, the prior is going to have a disproportionate effect. The priors for the parameters in our model can be chosen with various justifications. We discuss two “camps” of priors: those that are informative and those that are ostensibly less informative–which we will refer to as weakly informative. We will briefly discuss informative priors and then spend the rest of this review discussing and applying weakly informative priors. 2.2 Informative priors An informative prior can be considered one which is based on results from previous studies. For example, both Turner et al. (2012) and Turner et al. (2015) generate predictive distributions from previous Cochrane reviews of meta-analyses. These predictive distributions can be used as informative priors for conducting new meta-analyses. In Turner et al. (2015), the informative priors are created for a variety of different types of binary-outcome studies, such as disease outcome or infection onset. The priors are informative in that they use estimates generated from modelling the meta-analysis data as the parameters in the priors. Rhodes, Turner, and Higgins (2015) also generate predictive distributions from previous meta-analyses using Cochrane reviews. In contrast to Turner et al. (2015), they focus on priors for continuous outcomes. They conduct a prior sensitivity analysis, demonstrating how the use of informative priors can dramatically change the between-study variance estimate, either increasing or reducing \\(\\tau^2\\) depending on the context. Taking a a different approach, Rhodes et al. (2016) consider how to generate informative priors using data-augmentation techniques. Specifically, they generate new data from inverse-gamma distributions based on previous studies, and add this generated data to the observed data. This approach actually stands in contrast to the fully Bayesian approach we have discussed so far, in that they are not actually using a prior for parameters in their model but are instead augmenting the observed data with previous data. This is a philosophically similar but mathematically different technique. 2.3 Weakly informative priors As mentioned, the choice of prior is a fairly important decision, but also a somewhat contentious one. The reason for this is that the choice brings together arguments from statistical theory, philosophy, and domain-specific expertise. There are certain statistical properties that must be considered in the choice of the prior, namely conjugacy and impropriety of the posterior. But these mathematical properties don’t dilute the real-world phenomenon that we are modelling, and thus philosophical arguments regarding what type of information the prior provides and expert opinion regarding the relevance of the information provided by the prior must always be taken into account. Weakly informative priors are those that do not consider information from previous studies but still constrain the estimates of the parameters to a realistic or meaningful range of values. They often have desirable mathematical properties as well. That is to say, all priors come with their own set of assumptions, so that there is no such thing as a non-informative prior, but it is possible to select priors that contribute less information than others (Gelman, Simpson, and Betancourt 2017). We will discuss three weakly informative priors previously used for Bayesian meta-analysis: inverse-gamma, half-t, and half-cauchy distributions. Following this discussion, we will apply these priors in our own prior sensitivity analysis. The inverse-gamma prior for \\(\\tau^2\\) can be written as \\[\\begin{gather} p(\\tau^2) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}(\\tau^2)^{-(\\alpha+1)}\\exp\\Bigg(\\frac{\\beta}{\\tau^2}\\Bigg) \\end{gather}\\] It is often used as a weakly informative prior due to the fact that it is conjugate for \\(\\tau^2\\) in the random effects model. However, the posterior is sensitive to the value of \\(\\alpha\\) and \\(\\beta\\) when \\(\\tau^2\\) is small (Gelman 2006). This means that the inverse-gamma is not strictly weakly informative, as it incorporates information based on ones choice of \\(\\alpha\\) and \\(\\beta\\). A weakly informative prior should be invariant to this sort of hyperparameter selection. Relatedly, Polson and Scott (2012) argue that the inverse-gamma distribution pulls \\(\\tau^2\\) values away from 0, which nullifies its weakly informative properties in the case where \\(\\tau^2\\) is small. We next consider the half-t prior. The half-t distribution is a special case of the folded-t distribution where the \\(\\mu\\) parameter (not shown) is equal to 0 . Gelman (2006) make the case for the use of this prior as a replacement to the inverse-gamma, in order to avoid the issues with inverse-gamma when \\(\\tau^2\\) is small. The half-t is defined as \\[\\begin{gather} p(\\tau) \\propto \\Bigg(1 + \\frac{1}{\\nu}\\Big(\\frac{\\tau}{2}\\Big)^2\\Bigg)^{-(\\nu+1)/2} \\tag{2.2} \\end{gather}\\] The half-cauchy distribution is a special case of the half-t distribution (and therefore the folded-t), where \\(\\nu=1\\) in Equation (2.2). More exactly, it is defined as \\[\\begin{gather} p(\\tau) = \\frac{(\\tau)^{-1/2}(1+\\tau^2)^{-1}}{\\beta(1/2,1/2)} \\end{gather}\\] where \\(\\beta\\) refers to the Beta function. It can allow for wider tails than the half-t, meaning that in the case of random effect models, it allows for larger estimates of the between-study variance (Sheng 2017). We have presented three weakly informative prior distributions that can realistically constrain the between-study variance, while also maintaining some semblance of mathematical justification in the context of the likelihoods used in Bayesian meta-analysis; this does not, however, shake the sense of the somewhat arbitrary nature of these choices. To this – abeit regarding only the half-cauchy – Polson and Scott (2012) say, Generalizing from this, each prior occupies the space of compromise between any staunch set of assumptions regarding the appropriate parameter values. Beyond that, one must apply such priors to their own meta-analysis of interest, and determine if, yes, indeed, these priors lead to reasonable results. That is, then, the next step that we take. References "],["bayesian-meta-analysis-on-ivermectin.html", "3 Bayesian meta-analysis on ivermectin 3.1 Sensitivity analysis", " 3 Bayesian meta-analysis on ivermectin Having discussed Bayesian methods for estimating random effects models in meta-analyses, with a particular focus on the use of weakly informative priors, we are now prepared to conduct a Bayesian meta-analysis of our own. The data this meta-analysis we use was reconstructed by Gelman (2022) in a blog post.1 This post discusses the effect of the anti-parasitic medication ivermectin. It should be noted that there is little evidence that ivermectin is an effective treatment for COVID-19, and studies around this area have been rife with pseudoscience and suspiscious data. The purpose of the blog post was to further discuss how one might draw false positive results in a meta-analysis, with a bayesian treatment of studies related to ivermectin, and so we extend that here. This data used in this analysis is on the log scale (log of the odds ratio), so that we can exponentiate the cofficients from our Bayesian model to get the relative risk (RR). The RR is the multiplicative factor by which the mean of individuals in group \\(x_i\\) is equal to \\(\\exp(B_i)\\) times the mean of individuals in the reference group, keeping all other covariates equal. For a RR of 50%, we say that the treatment resulted in a 50% improvement relative to the control. In the case of the results presented here, we say that patients treated with ivermectin had a \\(p\\)% improvement, depending on the outcome measured in the studies. We first fit a random-effects model on the data using Stan, and then conduct a sensitivity analysis. The Stan models, including their priors, can be found at https://github.com/saverymax/bayesian-meta-analysis-bookdown. 3.1 Sensitivity analysis Having introduced the topic of our meta-analysis and the means by which we will conduct it, we now proceed to discuss the extent to which the posterior estimates and intervals change when the priors on the between-study variance are altered. In Bayesian data analysis, this is known as a prior sensitivity analysis. The intent of our sensitivity analysis is to determine the effect that altering the weak prior has on our posterior estimates and conclusions of the meta-analysis. As described above, we use the inverse-gamma,2 the half-t distribution, and the half-cauchy, roughly following the work Williams, Rast, and Bürkner (2018). For reference, we also include a uniform prior, though this is not recommended due to the improper posteriors that can result from its use (Gelman 2006). We use the following priors with the hyperparameters shown in Equation (3.1), following Williams, Rast, and Bürkner (2018). The prior densities are shown in Figure 3.1. We also include a uniform prior of U\\((0,10)\\) to demonstrate the effect of an unrealistic prior. It is unreasonable to assume that the between-study variance is distributed uniformly from 0 all the way to 10, 10 being quite large in this context. \\[\\begin{equation} \\begin{gathered} \\tau \\sim \\text{U}(0, 10) \\\\ \\tau \\sim \\text{Inverse-gamma}(1,0.15)\\\\ \\tau \\sim \\text{Half-t}(0, 0.5) \\\\ \\tau \\sim \\text{Half-cauchy}(0, 0.5) \\end{gathered} \\tag{3.1} \\end{equation}\\] Figure 3.1: Prior densities used in sensitivity analysis The posterior estimates on the log of the odds scale can be found in Section 4.1 of the appendix. For brevity, we do not discuss them here. However, Figure 3.2 does show the posterior density plots of these parameters. Posterior plots were generated with the R package bayesplot (Gabry et al. 2019). Important to note is that the parameters estimated with the uniform prior have the largest tails, whereas those from the model using the half-t have smaller tails. This is to be expected. The half-t imposes more constraints than the uniform or the half-cauchy. Despite the theoretical recommendations against the inverse-gamma, in this case the corresponding posteriors are relatively similar to those of the half-t or half-cauchy. Figure 3.2: Posterior densities of parameters estimated from random effects model, log-odds scale Notice the \\(\\theta_{\\text{new}}\\) parameter in Figure 3.2. This is a simulated estimate of the effect of ivermectin for some hypothetical future study, where the effect is drawn from \\(N(\\mu,\\tau)\\) and the specific values of \\(\\mu\\) and \\(\\tau\\) are sampled from their respective posteriors. This takes into account the uncertainty associated with the parameters and the sampling uncertainty of conducting a new study. It means that, given all the uncertainty associated with different types of studies included in the meta-analysis, if we were to conduct a new study on the effect of ivermectin as a treatment for COVID-19, the distribution of \\(\\theta_{\\text{new}}\\) will approximate the future effects that could be found in new studies. Figure 3.3 shows the posteriors for the between study deviation. We can see that the uniform prior allows for the widest distribution of \\(\\tau\\), whereas the half-t allows for the smallest. Figure 3.3: Posterior densities of tau We can then proceed to discuss the changes in the RR ratio. Table 3.1 shows the RR estimates of \\(\\mu\\) and - \\(\\theta_{\\text{new}}\\) for all different priors. We can see that the mean estimates themselves do not change in large amounts, which makes sense given that the only difference between the models presented here is the prior on the between-study variance. So while we don’t expect the point estimates to change, the credible intervals for these point estimates will. For example, we can see that the interval for \\(\\mu\\) goes from \\((0.2703, 0.9669)\\) when using the uniform prior on \\(\\tau\\) to \\((0.3192, 0.8303)\\) and \\((0.3342, 0.7796)\\) for the half-cauchy and half-t priors, respectively. Even more interesting, the interval for \\(\\theta_{\\text{new}}\\) goes from \\((0.1872, 1.3982)\\) when using the half-cauchy prior to \\((0.2755, 0.9794)\\) when using the half-t. This is indicative of the extent to which our meta-analysis conclusions can change based on the prior; in the half-cauchy case we would say that a future effect could result in a positive or negative change in outcome for ivermectin treatment, but when using the half-t we would conclude that ivermectin has either a negligible effect to a large positive effect. But in either case, the intervals are very wide. It is also important to mention that while the average RR of \\(\\mu\\) is less than 1 in all models, \\(\\theta_{\\text{new}}\\) takes quite a larger range, including values larger than 1 in the 90% credible interval. In general, from this set of studies included in the meta-analysis, such a result makes it difficult to draw conclusions about ivermectin one way or the other. It may be that these studies are too heterogeneous to find conclusive evidence. This will be discussed further in the conclusion. Table: Table 3.1: Relative Risk posterior estimates, with different priors on \\(\\tau\\). Distribution Parameter Mean 5% 95% Uniform \\(\\mu\\) 0.5099 0.2703 0.9669 \\(\\theta_{\\text{new}}\\) 0.5040 0.0977 2.6799 IG \\(\\mu\\) 0.5118 0.3123 0.8284 \\(\\theta_{\\text{new}}\\) 0.5144 0.1998 1.3313 Half-c \\(\\mu\\) 0.5118 0.3192 0.8303 \\(\\theta_{\\text{new}}\\) 0.5181 0.1872 1.3982 Half-t \\(\\mu\\) 0.5173 0.3342 0.7796 \\(\\theta_{\\text{new}}\\) 0.5188 0.2755 0.9794 Figure 3.4 shows the credible intervals for the study-specific effects \\(\\theta_i\\), \\(\\mu\\), and \\(\\theta_{\\text{new}}\\). This nicely illustrates the effect of our prior sensitivity analysis: The intervals for the uniform prior are really large compared to all other priors. While the intervals of the study-specific effects when using the inverse gamma and half-cauchy priors often include 1, the more informative half-t limits the spread of these intervals. Therefore, the conclusions of the meta-analysis need to be qualified based on this sensitivity analysis. At this point, it becomes less a statistical question and more one for the biomedical domain. Which of these studies has methodological errors, or are there other factors causing the observed effects to vary considerably and be quite sensitive to choice of prior? This question was discussed considerably in the medical literature and in social media; thus it is here we choose to conclude our prior sensitivity analysis. Figure 3.4: Equal tail credible intervals, for RR of posterior estimates References "],["appendix.html", "4 Appendix 4.1 Posterior estimates 4.2 Tau posteriors", " 4 Appendix 4.1 Posterior estimates Each table shows the posterior point estimates, under the log-scale and in terms of the relative risk. Table 4.1: Posterior estimates, with uniform prior on tau variable mean sd q5 q95 mu -0.6558 0.4033 -1.2738 0.0133 tau 0.8904 0.5158 0.1829 1.8271 theta[1] -0.9804 0.8147 -2.4492 0.2443 theta[2] -1.3686 0.4966 -2.1961 -0.5571 theta[3] 0.0085 0.9568 -1.3014 1.8031 theta[4] -1.2181 0.9390 -2.9209 0.0280 theta[5] -0.2948 0.8805 -1.5495 1.3458 theta[6] -0.7700 0.8065 -2.1600 0.5036 theta[7] -0.9929 0.8668 -2.5273 0.3100 theta[8] -0.7999 0.5918 -1.7952 0.1322 theta[9] -1.0475 0.8582 -2.6033 0.1768 theta[10] -0.2919 0.3140 -0.8073 0.2160 theta[11] -0.1814 0.6123 -1.0760 0.8710 theta_new -0.6764 1.1046 -2.4826 1.1218 Table 4.2: Relative Risk posterior estimates, with uniform prior on tau variable mean sd q5 q95 mu 0.5190 1.4967 0.2798 1.0134 theta[1] 0.3752 2.2584 0.0864 1.2767 theta[2] 0.2545 1.6431 0.1112 0.5729 theta[3] 1.0086 2.6034 0.2722 6.0684 theta[4] 0.2958 2.5573 0.0539 1.0284 theta[5] 0.7447 2.4121 0.2124 3.8411 theta[6] 0.4630 2.2401 0.1153 1.6547 theta[7] 0.3705 2.3792 0.0799 1.3634 theta[8] 0.4494 1.8073 0.1661 1.1414 theta[9] 0.3508 2.3589 0.0740 1.1934 theta[10] 0.7468 1.3688 0.4461 1.2411 theta[11] 0.8341 1.8447 0.3410 2.3893 theta_new 0.5085 3.0179 0.0835 3.0704 Table 4.3: Posterior estimates, with inverse-gamma prior on tau variable mean sd q5 q95 mu -0.6764 0.3051 -1.1855 -0.1672 tau 0.4195 0.3406 0.0609 1.0770 theta[1] -0.7825 0.5548 -1.7703 -0.0172 theta[2] -1.0360 0.4569 -1.8777 -0.3938 theta[3] -0.4254 0.6222 -1.2023 0.7611 theta[4] -0.8652 0.6166 -2.0291 -0.0866 theta[5] -0.5368 0.5680 -1.3565 0.4568 theta[6] -0.6880 0.5579 -1.5663 0.1693 theta[7] -0.7933 0.5511 -1.7731 -0.0247 theta[8] -0.7217 0.4369 -1.4690 -0.0444 theta[9] -0.8151 0.5842 -1.9102 -0.0614 theta[10] -0.4333 0.2997 -0.9040 0.0824 theta[11] -0.4469 0.4570 -1.0850 0.4092 theta_new -0.6521 0.6101 -1.6085 0.2682 Table 4.4: Relative Risk posterior estimates, with inverse-gamma prior on tau variable mean sd q5 q95 mu 0.5085 1.3567 0.3056 0.8460 theta[1] 0.4573 1.7415 0.1703 0.9829 theta[2] 0.3549 1.5792 0.1529 0.6745 theta[3] 0.6535 1.8631 0.3005 2.1407 theta[4] 0.4210 1.8527 0.1315 0.9170 theta[5] 0.5846 1.7648 0.2575 1.5791 theta[6] 0.5026 1.7470 0.2088 1.1845 theta[7] 0.4524 1.7351 0.1698 0.9756 theta[8] 0.4859 1.5479 0.2302 0.9566 theta[9] 0.4426 1.7936 0.1481 0.9405 theta[10] 0.6483 1.3495 0.4049 1.0859 theta[11] 0.6396 1.5794 0.3379 1.5055 theta_new 0.5210 1.8406 0.2002 1.3075 Table 4.5: Posterior estimates, with half-t prior on tau variable mean sd q5 q95 mu -0.6627 0.2541 -1.0930 -0.2537 tau 0.2278 0.1685 0.0167 0.5390 theta[1] -0.6912 0.3778 -1.3406 -0.1339 theta[2] -0.8605 0.3642 -1.5096 -0.3398 theta[3] -0.5844 0.3638 -1.1409 0.0263 theta[4] -0.7312 0.3879 -1.4441 -0.1882 theta[5] -0.6139 0.3667 -1.1761 -0.0173 theta[6] -0.6757 0.3638 -1.2736 -0.1141 theta[7] -0.6995 0.3764 -1.3705 -0.1383 theta[8] -0.6867 0.3411 -1.2646 -0.1392 theta[9] -0.7124 0.3746 -1.3593 -0.1577 theta[10] -0.5105 0.2655 -0.9383 -0.0623 theta[11] -0.5615 0.3431 -1.0746 0.0277 theta_new -0.6681 0.3788 -1.2911 -0.0826 Table 4.6: Relative Risk posterior estimates, with half-t prior on tau variable mean sd q5 q95 mu 0.5155 1.2893 0.3352 0.7760 theta[1] 0.5010 1.4591 0.2617 0.8747 theta[2] 0.4229 1.4394 0.2210 0.7119 theta[3] 0.5574 1.4388 0.3195 1.0267 theta[4] 0.4813 1.4739 0.2360 0.8284 theta[5] 0.5412 1.4429 0.3085 0.9828 theta[6] 0.5088 1.4387 0.2798 0.8922 theta[7] 0.4968 1.4570 0.2540 0.8708 theta[8] 0.5032 1.4065 0.2823 0.8701 theta[9] 0.4904 1.4544 0.2569 0.8541 theta[10] 0.6002 1.3041 0.3913 0.9396 theta[11] 0.5704 1.4093 0.3414 1.0281 theta_new 0.5127 1.4606 0.2750 0.9207 Table 4.7: Posterior estimates, with half-cauchy prior on tau variable mean sd q5 q95 mu -0.6742 0.3054 -1.1743 -0.1751 tau 0.4926 0.3525 0.0521 1.1582 theta[1] -0.8300 0.5880 -1.8500 0.0165 theta[2] -1.1037 0.4519 -1.9019 -0.4458 theta[3] -0.3774 0.6502 -1.2496 0.8395 theta[4] -0.9146 0.6323 -2.0852 -0.0854 theta[5] -0.5095 0.5985 -1.3682 0.5812 theta[6] -0.7216 0.6031 -1.7244 0.1890 theta[7] -0.8189 0.6017 -1.8703 0.0267 theta[8] -0.7503 0.4544 -1.5234 -0.0326 theta[9] -0.8312 0.6035 -1.8771 0.0208 theta[10] -0.4017 0.3068 -0.8711 0.1260 theta[11] -0.3990 0.4869 -1.1029 0.5113 theta_new -0.6706 0.6995 -1.7725 0.3930 Table 4.8: Relative Risk posterior estimates, with half-cauchy prior on tau variable mean sd q5 q95 mu 0.5095 1.3571 0.3090 0.8394 theta[1] 0.4361 1.8003 0.1572 1.0167 theta[2] 0.3316 1.5713 0.1493 0.6403 theta[3] 0.6856 1.9158 0.2866 2.3152 theta[4] 0.4007 1.8820 0.1243 0.9181 theta[5] 0.6008 1.8194 0.2546 1.7883 theta[6] 0.4860 1.8277 0.1783 1.2081 theta[7] 0.4409 1.8253 0.1541 1.0270 theta[8] 0.4722 1.5752 0.2180 0.9679 theta[9] 0.4355 1.8285 0.1530 1.0210 theta[10] 0.6692 1.3591 0.4185 1.1343 theta[11] 0.6710 1.6273 0.3319 1.6674 theta_new 0.5114 2.0127 0.1699 1.4814 4.2 Tau posteriors Here we show the posterior for tau as generated under the different priors. Figure 4.1: Posterior densities of tau "],["references.html", "5 References", " 5 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
